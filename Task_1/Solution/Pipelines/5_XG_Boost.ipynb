{"cells":[{"cell_type":"markdown","source":"# Template Pipeline\nNormalisation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**-**  \nImputation 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Median**  \nOutlier Detection&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Z Score**  \nImputation 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Median**  \nFeature Selection&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Implicit to model**  \nModel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Lasso Regression**\n","metadata":{"tags":[],"output_cleared":false,"cell_id":"00000-f69098f1-6e4d-4b9e-ad3a-cadcdee47f30"}},{"cell_type":"markdown","source":"## Imports","metadata":{"tags":[],"output_cleared":false,"cell_id":"00001-9ab1435f-d16e-45da-8e08-293f26f49852"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/gdrive')","metadata":{"tags":[],"cell_id":"00002-dc8c6205-5d71-4c30-97a7-b18c91457131"},"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"id":"_1DeRFrUzVGn","output_cleared":false,"source_hash":"b87af053","execution_millis":43,"cell_id":"00002-1b7ae4cc-02c7-4af3-a373-4ecde81f02cb","execution_start":1602693265554},"source":"# General\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# ML\nfrom sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LassoCV, LassoLarsCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\n\nimport xgboost as xgb\n\n# Custom\nimport sys,os\n# %cd /content/gdrive/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution\n# sys.path.append('/content/gdrive/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution')\nsys.path.append('/home/jovyan/work/AML/Task_1/Solution') # I would like a cleaner solution but works for now\nimport Components.Imputation as Imputation\nimport Components.Outlier_Detection_1D as Outlier_Detection_1D\nimport Components.Outlier_Detection_ND as Outlier_Detection_ND\nimport Components.Feature_Selection as Feature_Selection\nimport Components.Normalisation as Normalisation\nimport Components.data_fetching as data_fetching\n\n# CAREFUL:\n# If you make changes to a custom module, you have to reload it, i.e rerun this cell\nimport importlib\nimportlib.reload(Imputation)\nimportlib.reload(Outlier_Detection_1D)\nimportlib.reload(Outlier_Detection_ND)\nimportlib.reload(Feature_Selection)\nimportlib.reload(Normalisation)\nimportlib.reload(data_fetching)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"<module 'Components.data_fetching' from '/home/jovyan/work/AML/Task_1/Solution/Components/data_fetching.py'>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"tags":[],"output_cleared":false,"cell_id":"00003-466aad76-e51d-4bf0-b9e2-34ee7c0e46a6"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"7e369ec5","execution_millis":81045,"cell_id":"00004-2461e103-37ad-425e-9b79-d795449ae8e1","execution_start":1602693267691},"source":"X, y = data_fetching.get_train_data()\nx_test_final = data_fetching.get_test_data()\n\nmv_mask = Imputation.missing_values_mask(X)\nX = Imputation.median(X)\nX = Normalisation.gaussian(X)\nX,y,mv_mask = Outlier_Detection_ND.magic_indices(X,y,n_outliers=50,mask=mv_mask)\nX = Outlier_Detection_1D.z_score(X,x_extra=x_test_final)\nX = X.mask(mv_mask) # Re-impute the ones we imputed before\nX,x_test_final = Imputation.iterative_regression2(X,x_test_final)\nx_test_final = data_fetching.get_test_data() # I don't want to impute x_test_final based on X as well... data leak maybe?\nx_test_final = Imputation.mean(x_test_final)\nX = Feature_Selection.select_percentile_mut_inf(X,y,test=x_test_final,percent=10)\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{"tags":[],"output_cleared":false,"cell_id":"00005-2d593c52-1f05-4666-916e-e34b1e3ecca6"}},{"cell_type":"markdown","source":"### Test","metadata":{"tags":[],"output_cleared":false,"cell_id":"00006-0c9ab840-46e4-4717-941b-f1505f508f59"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"f7873561","execution_millis":2625108,"cell_id":"00007-91c69408-1e3c-4977-aac8-7aed8b239ae1","execution_start":1602689981458},"source":"# pipe = Pipeline([('feature_selection', SelectFromModel(LassoLarsCV())),\n# ('regressor', GradientBoostingRegressor(n_estimators=100))])\n\ngbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(x_train, y_train)\npredictions = gbm.predict(test_X)\n\nprint('Train Score:')\ny_pred_train = gbm.predict(x_train)\ntrain_score = r2_score(y_train, y_pred_train)\nprint(train_score)\n\nprint('Test Score')\ny_pred_test = gbm.predict(x_test)\ntest_score = r2_score(y_test, y_pred_test)\nprint(test_score)","execution_count":6,"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-42db4b5ed0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ('regressor', GradientBoostingRegressor(n_estimators=100))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    832\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"d1245ac6","execution_start":1602686189706,"execution_millis":200481,"cell_id":"00008-02f15656-c9b9-40df-91e1-b2db80283f3c"},"source":"scores = cross_val_score(pipe, x_train, np.ravel(y_train), cv=5, scoring='r2')\nprint(scores)\nprint(np.mean(scores))","execution_count":23,"outputs":[{"name":"stdout","text":"[0.56811479 0.51315291 0.55132365 0.52312509 0.60499194]\n0.5521416777686738\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Final Prediction","metadata":{"tags":[],"output_cleared":false,"cell_id":"00009-80d80a53-bc1b-4a01-b9df-45c34740010c"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"b65ef699","execution_millis":1,"execution_start":1602685416658,"cell_id":"00010-2445c6ec-ca05-428d-9653-1259fde573d2"},"source":"pipe.fit(X, np.ravel(y))\n\nx_test_final = data_fetching.get_test_data()\nx_test_final = Imputation.iterative_regression2(x_test_final,X)\n# Note: They said no outliers were introduced in x_test_final so no need to perform outlier detection\ny_pred = pipe.predict(x_test_final,X)\nplt.hist(y_pred)\n\ny_pred_pd = pd.DataFrame(data=y_pred, columns=[\"y\"])\ny_pred_pd.to_csv('../../Predictions/RFE40_GradientBoosting.csv', index_label='id')\n","execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pipe' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-067263e08cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_test_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterative_regression2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"]}]}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"task1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"deepnote_notebook_id":"135248f8-93a0-4e77-95e6-25779324fefc","deepnote_execution_queue":[{"cellId":"00004-2461e103-37ad-425e-9b79-d795449ae8e1","sessionId":"2bf331bc-984b-450b-a6e8-e47bbe00755f","msgId":"f4e98d22-39b4-436b-bde3-93693cd86d16"}]}}
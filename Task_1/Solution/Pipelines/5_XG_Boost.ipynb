{"cells":[{"cell_type":"markdown","source":"# Template Pipeline\nNormalisation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**-**  \nImputation 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Median**  \nOutlier Detection&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Z Score**  \nImputation 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Median**  \nFeature Selection&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Implicit to model**  \nModel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Lasso Regression**\n","metadata":{"tags":[],"output_cleared":false,"cell_id":"00000-f69098f1-6e4d-4b9e-ad3a-cadcdee47f30"}},{"cell_type":"markdown","source":"## Imports","metadata":{"tags":[],"output_cleared":false,"cell_id":"00001-9ab1435f-d16e-45da-8e08-293f26f49852"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-dc8c6205-5d71-4c30-97a7-b18c91457131"},"source":"from google.colab import drive\ndrive.mount('/content/gdrive')","execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xgboost\n","metadata":{"tags":[],"cell_id":"00003-f2dffc3a-dae5-4e3f-8ea3-a6e219cc971d","output_cleared":false,"source_hash":"2a8835f0","execution_start":1602704092722,"execution_millis":9258},"outputs":[{"name":"stdout","text":"Collecting xgboost\n  Downloading xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9 MB)\n\u001b[K     |████████████████████████████████| 148.9 MB 142 kB/s  eta 0:00:01 15.5 MB 12.2 MB/s eta 0:00:11[K     |████████████▉                   | 59.6 MB 12.2 MB/s eta 0:00:08 eta 0:00:01��███████████▎| 145.3 MB 69.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy in /opt/venv/lib/python3.7/site-packages (from xgboost) (1.5.2)\nRequirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from xgboost) (1.19.2)\nInstalling collected packages: xgboost\nSuccessfully installed xgboost-1.2.1\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"id":"_1DeRFrUzVGn","output_cleared":false,"source_hash":"bad8611","execution_millis":33,"cell_id":"00002-1b7ae4cc-02c7-4af3-a373-4ecde81f02cb","execution_start":1602704101987},"source":"# General\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# ML\nfrom sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LassoCV, LassoLarsCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\n\nimport xgboost as xgb\n\n# Custom\nimport sys,os\n# %cd /content/gdrive/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution\n# sys.path.append('/content/gdrive/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution')\nsys.path.append('/home/jovyan/work/AML/Task_1/Solution') # I would like a cleaner solution but works for now\nimport Components.Imputation as Imputation\nimport Components.Outlier_Detection_1D as Outlier_Detection_1D\nimport Components.Outlier_Detection_ND as Outlier_Detection_ND\nimport Components.Feature_Selection as Feature_Selection\nimport Components.Normalisation as Normalisation\nimport Components.data_fetching as data_fetching\n\n# CAREFUL:\n# If you make changes to a custom module, you have to reload it, i.e rerun this cell\nimport importlib\nimportlib.reload(Imputation)\nimportlib.reload(Outlier_Detection_1D)\nimportlib.reload(Outlier_Detection_ND)\nimportlib.reload(Feature_Selection)\nimportlib.reload(Normalisation)\nimportlib.reload(data_fetching)","outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<module 'Components.data_fetching' from '/home/jovyan/work/AML/Task_1/Solution/Components/data_fetching.py'>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"tags":[],"output_cleared":false,"cell_id":"00003-466aad76-e51d-4bf0-b9e2-34ee7c0e46a6"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"cecf9624","execution_millis":19716,"cell_id":"00004-2461e103-37ad-425e-9b79-d795449ae8e1","execution_start":1602704417198},"source":"X, y = data_fetching.get_train_data()\nx_test_final = data_fetching.get_test_data()\n\nmv_mask = Imputation.missing_values_mask(X)\nX = Imputation.median(X)\nX = Normalisation.gaussian(X)\nX,y,mv_mask = Outlier_Detection_ND.magic_indices(X,y,n_outliers=10,mask=mv_mask)\nX = Outlier_Detection_1D.z_score(X) #,x_extra=x_test_final)\nX = X.mask(mv_mask) # Re-impute the ones we imputed before\nX = Imputation.mean(X)\n# X,x_test_final = Imputation.iterative_regression2(X,x_test_final)\nx_test_final = data_fetching.get_test_data() # I don't want to impute x_test_final based on X as well... data leak maybe?\nx_test_final = Imputation.mean(x_test_final)\nX,x_test_final = Feature_Selection.select_percentile_mut_inf(X,y,x_test=x_test_final,percent=50)\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)","outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass percentile=50 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n/opt/venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Model Training","metadata":{"tags":[],"output_cleared":false,"cell_id":"00005-2d593c52-1f05-4666-916e-e34b1e3ecca6"}},{"cell_type":"markdown","source":"### Test","metadata":{"tags":[],"output_cleared":false,"cell_id":"00006-0c9ab840-46e4-4717-941b-f1505f508f59"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"b966260","execution_millis":146044,"cell_id":"00007-91c69408-1e3c-4977-aac8-7aed8b239ae1","execution_start":1602705168494},"source":"gbm = xgb.XGBRegressor(max_depth=3, n_estimators=75, learning_rate=0.05, alpha=1, objective='reg:squarederror').fit(x_train, y_train)\n\nkfold = KFold(n_splits=10)\nresults = cross_val_score(gbm, x_train, y_train, cv=kfold)\nprint(results)\nprint(results.mean())\n\nprint('Train Score')\ny_pred_train = gbm.predict(x_train)\ntest_score = r2_score(y_train, y_pred_train)\nprint(test_score)\n\nprint('Test Score')\ny_pred_test = gbm.predict(x_test)\ntest_score = r2_score(y_test, y_pred_test)\nprint(test_score)","outputs":[{"name":"stdout","text":"[0.52196672 0.52751118 0.52042321 0.44937897 0.45876363 0.58604072\n 0.52967402 0.49833196 0.6046143  0.51960716]\n0.521631187746819\nTrain Score\n0.7553048082770955\nTest Score\n0.5988531138208393\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Final Prediction","metadata":{"tags":[],"output_cleared":false,"cell_id":"00009-80d80a53-bc1b-4a01-b9df-45c34740010c"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":true,"source_hash":null,"execution_millis":1527,"cell_id":"00010-2445c6ec-ca05-428d-9653-1259fde573d2","execution_start":1602697780422},"source":"gbm = xgb.XGBRegressor(max_depth=3, n_estimators=75, learning_rate=0.05, objective='reg:squarederror').fit(X, y)\n\ny_pred = gbm.predict(x_test_final)\nplt.hist(y_pred)\nprint(\"Train Score:\", r2_score(y, gbm.predict(X)))\n\ny_pred_pd = pd.DataFrame(data=y_pred, columns=[\"y\"])\n# y_pred_pd.to_csv('../../Predictions/RFE40_GradientBoosting.csv', index_label='id')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00011-2eaed55c-5a38-4093-83dc-5670413d7d11"},"source":"# Random test\nX2, y2 = data_fetching.get_train_data()\nx_test_final2 = data_fetching.get_test_data()\n\ngbm = xgb.XGBRegressor(objective='reg:squarederror').fit(X2, y2)\n\ny_pred = gbm.predict(x_test_final2)\nplt.hist(y_pred)\nprint(\"Train Score:\", r2_score(y2, gbm.predict(X2)))\n\n# y_pred_pd = pd.DataFrame(data=y_pred, columns=[\"y\"])\n# y_pred_pd.to_csv('../../Predictions/RFE40_GradientBoosting.csv', index_label='id')","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"task1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"deepnote_notebook_id":"135248f8-93a0-4e77-95e6-25779324fefc","deepnote_execution_queue":[]}}
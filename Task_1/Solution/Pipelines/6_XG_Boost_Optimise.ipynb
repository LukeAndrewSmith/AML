{"cells":[{"cell_type":"markdown","source":"# Template Pipeline\nNormalisation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**-**  \nImputation 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Median**  \nOutlier Detection&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Z Score**  \nImputation 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Median**  \nFeature Selection&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Implicit to model**  \nModel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n**Lasso Regression**\n","metadata":{"tags":[],"output_cleared":false,"cell_id":"00000-45a9ad12-e255-42f8-a071-14b20744d049"}},{"cell_type":"markdown","source":"## Imports","metadata":{"tags":[],"output_cleared":false,"cell_id":"00001-fedbb398-29dd-435c-80a7-505c833246bf"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-de68acae-2292-40a0-975e-ddad0c8abd95"},"source":"from google.colab import drive\ndrive.mount('/content/gdrive')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1DeRFrUzVGn","output_cleared":false,"source_hash":"9b6e5a50","execution_millis":7,"cell_id":"00003-4c276560-2c50-4073-a75b-f79929856cc9","execution_start":1602774048586},"source":"# General\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# ML\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer, SimpleImputer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_selection import RFE\n\nimport xgboost as xgb\n\n# Custom\nimport sys,os\n%cd /content/fuck/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution\nsys.path.append('/content/fuck/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution')\n# sys.path.append('/home/jovyan/work/AML/Task_1/Solution') # I would like a cleaner solution but works for now\n# import Components.Imputation as Imputation\n# import Components.Outlier_Detection_1D as Outlier_Detection_1D\n# import Components.Outlier_Detection_ND as Outlier_Detection_ND\n# import Components.Feature_Selection as Feature_Selection\n# import Components.Normalisation as Normalisation\nimport Components.data_fetching as data_fetching\n\n# # CAREFUL:\n# # If you make changes to a custom module, you have to reload it, i.e rerun this cell\nimport importlib\n# importlib.reload(Imputation)\n# importlib.reload(Outlier_Detection_1D)\n# importlib.reload(Outlier_Detection_ND)\n# importlib.reload(Feature_Selection)\n# importlib.reload(Normalisation)\nimportlib.reload(data_fetching)","outputs":[{"name":"stdout","text":"[Errno 2] No such file or directory: '/content/fuck/My Drive/ETHZ/Autumn2020/AML/Git/AML/Task_1/Solution'\n/home/jovyan\n","output_type":"stream"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<module 'Components.data_fetching' from '/home/jovyan/work/AML/Task_1/Solution/Components/data_fetching.py'>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Pipeline Optimisatoin","metadata":{"tags":[],"output_cleared":false,"cell_id":"00004-6983450e-d175-48e8-80fb-edf934ab347f"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-30f41914-53e5-44f9-964b-ff0fc734a30c","output_cleared":false,"source_hash":"5e11ebf5","execution_millis":1319,"execution_start":1602765482772},"source":"X,y = data_fetching.get_train_data()\ny = np.ravel(y)\nx_test_final = data_fetching.get_test_data()\n\n# x_train, x_test, y_train, y_test = train_test_split(X, np.ravel(y), test_size=0.15, random_state=0)\n# y_train = np.ravel(y_train)\n# y_train = np.ravel(y_test)","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-69c8f127-dbd8-4f5c-b825-24a75726a468","output_cleared":true,"source_hash":null,"execution_millis":6853,"execution_start":1602765580806},"source":"nrm = QuantileTransformer(output_distribution='normal')\n# imp = IterativeImputer(missing_values=np.nan, max_iter=10, initial_strategy='median' ,random_state=0)\nimp = SimpleImputer(strategy='mean')\nrfe = RFE(Ridge())\nboost = xgb.XGBRegressor(objective='reg:squarederror')\n\npipe = Pipeline(steps=[('normalise', nrm),\n                        ('impute', imp),\n                        ('feature_select', rfe),\n                        ('regress', boost)])\n\n# Normalisation\nn_quants = [50,100]\n# Imputer\n# n_nearest_features = [10,20]\n# Feature Selection\nn_features = [30,50]\n# Model\n# max_depth = [2,3,4]\nlearning_rate = [0.05, 0.15]\nn_estimators = [100, 200]\n\nparameters = dict(normalise__n_quantiles=n_quants,\n                    # impute__n_nearest_features=n_nearest_features,\n                    feature_select__n_features_to_select=n_features,\n                    regress__learning_rate=learning_rate,\n                    regress__n_estimators=n_estimators)\n\nclf = GridSearchCV(pipe, parameters)\nclf.fit(X, y)\n\n# View The Best Parameters\nprint('n_quantiles=', clf.best_estimator_.get_params()['normalise__n_quantiles'])\n# print('n_nearest_features=', clf.best_estimator_.get_params()['impute__n_nearest_features'])\nprint('n_features_to_select=', clf.best_estimator_.get_params()['feature_select__n_features_to_select'])\nprint('learning_rate=', clf.best_estimator_.get_params()['regress__learning_rate'])\nprint('n_estimators=', clf.best_estimator_.get_params()['regress__n_estimators'])\nbest_n_quantiles= clf.best_estimator_.get_params()['normalise__n_quantiles']\n# best_n_nearest_features= clf.best_estimator_.get_params()['impute__n_nearest_features']\nbest_n_features_to_select= clf.best_estimator_.get_params()['feature_select__n_features_to_select']\nbest_learning_rate= clf.best_estimator_.get_params()['regress__learning_rate']\nbest_n_estimators= clf.best_estimator_.get_params()['regress__n_estimators']\n\n# Output\n# n_quantiles= 50\n# n_features_to_select= 50\n# learning_rate= 0.05\n# n_estimators= 200","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing: Unused","metadata":{"tags":[],"output_cleared":false,"cell_id":"00007-943ef10f-4357-4a5c-ad84-958ad1988cf2"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"b966260","execution_millis":146044,"execution_start":1602705168494,"cell_id":"00009-a9fb083d-d3a7-4daf-b4ff-d348c6215e1f"},"source":"kfold = KFold(n_splits=10)\nresults = cross_val_score(clf, x_train, y_train, cv=kfold)\nprint(results)\nprint(results.mean())\n\nprint('Train Score')\ny_pred_train = clf.predict(x_train)\ntest_score = r2_score(y_train, y_pred_train)\nprint(test_score)\n\nprint('Test Score')\ny_pred_test = clf.predict(x_test)\ntest_score = r2_score(y_test, y_pred_test)\nprint(test_score)","execution_count":null,"outputs":[{"name":"stdout","text":"[0.52196672 0.52751118 0.52042321 0.44937897 0.45876363 0.58604072\n 0.52967402 0.49833196 0.6046143  0.51960716]\n0.521631187746819\nTrain Score\n0.7553048082770955\nTest Score\n0.5988531138208393\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Final Prediction","metadata":{"tags":[],"output_cleared":false,"cell_id":"00010-8f38a686-19ab-42c8-ac87-4cc7e46b48dd"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":true,"source_hash":null,"execution_millis":1527,"execution_start":1602697780422,"cell_id":"00011-12c13010-5fc2-4efd-9a8c-a8a1c9530532"},"source":"# pipe = Pipeline(steps=[('normalise', nrm),\n#                         ('impute', imp),\n#                         ('feature_select', rfe),\n#                         ('regress', boost)])\n\n# clf = GridSearchCV(pipe, normalise__n_quantiles=best_n_quantiles,\n#                     # impute__n_nearest_features=best_n_nearest_features,\n#                     feature_select__n_features_to_select=best_n_features_to_select,\n#                     regress__learning_rate=best_learning_rate,\n#                     regress__n_estimators=best_n_estimators)\n# clf.fit(X, y)\n\ny_pred = clf.predict(x_test_final)\nplt.hist(y_pred)\nprint(\"Train Score:\", r2_score(y, clf.predict(X)))\n\ny_pred_pd = pd.DataFrame(data=y_pred, columns=[\"y\"])\ny_pred_pd.to_csv('../Predictions/XGBoost_Optimised.csv', index_label='id')","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"task1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"deepnote_notebook_id":"82227e64-999a-4665-9cd4-1c10481fafda","deepnote_execution_queue":[]}}
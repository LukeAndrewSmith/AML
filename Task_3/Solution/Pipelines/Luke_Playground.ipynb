{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biosppy in /opt/conda/lib/python3.7/site-packages (0.6.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from biosppy) (0.23.2)\n",
      "Requirement already satisfied: shortuuid in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.0.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from biosppy) (2.10.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from biosppy) (3.3.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.15.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.18.5)\n",
      "Requirement already satisfied: bidict in /opt/conda/lib/python3.7/site-packages (from biosppy) (0.21.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->biosppy) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->biosppy) (0.17.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (7.2.0)\n",
      "Collecting neurokit2\n",
      "  Downloading neurokit2-0.0.41-py2.py3-none-any.whl (983 kB)\n",
      "\u001b[K     |████████████████████████████████| 983 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from neurokit2) (1.18.5)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from neurokit2) (0.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from neurokit2) (1.5.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from neurokit2) (3.3.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from neurokit2) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn->neurokit2) (0.23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->neurokit2) (2020.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->neurokit2) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->neurokit2) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->neurokit2) (1.15.0)\n",
      "Installing collected packages: neurokit2\n",
      "Successfully installed neurokit2-0.0.41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Components.data_fetching' from '../Components/data_fetching.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General\n",
    "! pip install biosppy\n",
    "! pip install neurokit2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import biosppy\n",
    "from biosppy.signals import ecg\n",
    "import neurokit2 as nk\n",
    "from pprint import pprint\n",
    "\n",
    "# ML\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Custom\n",
    "import sys,os\n",
    "sys.path.append( '.' )\n",
    "sys.path.append( '..' )\n",
    "import Components.Outlier_Detection as Outlier_Detection\n",
    "import Components.Feature_Selection as Feature_Selection\n",
    "import Components.Normalisation as Normalisation\n",
    "import Components.data_fetching as data_fetching\n",
    "\n",
    "\n",
    "# CAREFUL:\n",
    "# If you make changes to a custom module, you have to reload it, i.e rerun this cell\n",
    "import importlib\n",
    "importlib.reload(Outlier_Detection)\n",
    "importlib.reload(Feature_Selection)\n",
    "importlib.reload(Normalisation)\n",
    "importlib.reload(data_fetching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_fetching.get_train_data()\n",
    "#x_test = data_fetching.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_cleaning(peaks):\n",
    "    # This method identifies tuples <p,q,r,s,t> which represent a single valid heartbeat,\n",
    "        # It therefore removes cases such as <_,_,r,s,t>, where p and q are missing\n",
    "        # It is robust to potential errors in the middle of the peak arrays\n",
    "    # Return:\n",
    "        # It return an array, A, of equal length arrays of peak location for p,q,r,s,t peaks\n",
    "        # A[:][i] represents a valid heartbeat tuple <p,q,r,s,t>\n",
    "\n",
    "    # median r_peak distance used later to check if the p_peak r_peak distance in valid\n",
    "    med = np.median(np.diff(peaks[0])) # TODO: MAKE SURE THIS IS VALID\n",
    "    \n",
    "    # Obtain valid <p,q,r,t> pairs\n",
    "    # assume p,q,r,t each ordered asc.\n",
    "        # for each possible <p,q,r,t>\n",
    "            # if p>q,r,t then we can never for a valid pair with q,r,t so drop q,r,t\n",
    "                # repeat until p<q,r,t\n",
    "                # same with p<q>r,t, p<q<r>t,\n",
    "            # cont until p<q<r<t, then check that p<q<r<t is feasible\n",
    "    i = -1\n",
    "    while i < len(peaks[0]):\n",
    "        i += 1\n",
    "        if i <= np.min(list(map(len, peaks)))-1:\n",
    "            for j in range(len(peaks)-1):\n",
    "                while (peaks[j][i] > peaks[j+1][i]):\n",
    "                    peaks[j+1].pop(i)\n",
    "            if peaks[-1][i] - peaks[0][i] > med:\n",
    "                peaks[0].pop(i)\n",
    "                i -= 1\n",
    "        else:\n",
    "            for i in range(len(peaks)):\n",
    "                peaks[i] = peaks[i][:np.min(list(map(len, peaks)))]\n",
    "            break\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(peaks):\n",
    "\n",
    "    features = []\n",
    "    \n",
    "    bpm = 18000 / np.mean(np.diff(peaks[2]))\n",
    "    features.append(bpm)\n",
    "    \n",
    "    ######################\n",
    "    # Single-peak measures\n",
    "        # For the single peak measure we wan't all the data that ecg_process found\n",
    "    # Variablity measures: single peak type\n",
    "    for i in range(len(peaks)):\n",
    "        peak = peaks[i]\n",
    "        diff = np.diff(peak)\n",
    "        features.append(np.mean(peak))\n",
    "        features.append(np.var(peak))\n",
    "        features.append(np.mean(diff))\n",
    "        features.append(np.var(diff))\n",
    "        \n",
    "    #####################\n",
    "    # Multi-peak measures\n",
    "        # For the multi-peak measure we require the combination of each peak identified at index i\n",
    "        # to repr\n",
    "    peaks = peaks_cleaning(peaks)\n",
    "    \n",
    "    # Variablity measures: multi peak types\n",
    "    for i in range(len(peaks)):\n",
    "        for j in range(len(peaks)):\n",
    "            diff = np.array(peaks[i])-np.array(peaks[j])\n",
    "            features.append(np.mean(diff))\n",
    "            features.append(np.var(diff))\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141, 405, 658, 1476, 1746, 2009, 2267, 2522, 2780, 3026],\n",
      " [170, 431, 678, 954, 1498, 1761, 2031, 2291, 2554, 2803, 3046],\n",
      " [183, 446, 706, 969, 1237, 1517, 1783, 2050, 2306, 2566, 2817, 3068],\n",
      " [209, 465, 746, 998, 1257, 1536, 1809, 2069, 2326, 2583, 2839, 3087],\n",
      " [288, 502, 803, 1084, 1289, 1572, 1852, 2109, 2685, 2872, 3124]]\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "ecg_signal = X.iloc[0].dropna()\n",
    "\n",
    "# Fetch peak arrays: [p,q,r,s,t]\n",
    "signals,_ = nk.ecg_process(signal, sampling_rate=300)\n",
    "peaks = [list(signals.index[signals[peak_type]==1]) for peak_type in [\"ECG_P_Peaks\",\"ECG_Q_Peaks\",\"ECG_R_Peaks\",\"ECG_S_Peaks\",\"ECG_T_Peaks\"]]\n",
    "\n",
    "pprint(peaks)\n",
    "f = feature_extraction(peaks)\n",
    "\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1:\n",
      "[[None, 405, 658, 1476, 1746, 2009, 2267, 2522, 2780, 3026],\n",
      " [170, 431, 678, 954, 1498, 1761, 2031, 2291, 2554, 2803, 3046],\n",
      " [183, 446, 706, 969, 1237, 1517, 1783, 2050, 2306, 2566, 2817, 3068],\n",
      " [209, 465, 746, 998, 1257, 1536, 1809, 2069, 2326, 2583, 2839, 3087],\n",
      " [288, 502, 803, 1084, 1289, 1572, 1852, 2109, 2685, 2872, 3124]]\n",
      "[[405, 658, 1476, 1746, 2009, 2522, 2780, 3026],\n",
      " [431, 678, 1498, 1761, 2031, 2554, 2803, 3046],\n",
      " [446, 706, 1517, 1783, 2050, 2566, 2817, 3068],\n",
      " [465, 746, 1536, 1809, 2069, 2583, 2839, 3087],\n",
      " [502, 803, 1572, 1852, 2109, 2685, 2872, 3124]]\n",
      "\n",
      "Test 2:\n",
      "[[141, 405, 658, 1476, 1746, 2009, 2267, 2522, 2780, 3026],\n",
      " [170, 431, 678, 954, 1498, 1761, 2031, 2291, 2554, 2803, 3046],\n",
      " [183, 446, 706, 969, 1237, None, 1783, 2050, 2306, 2566, 2817, 3068],\n",
      " [209, 465, 746, 998, 1257, 1536, 1809, 2069, 2326, 2583, 2839, 3087],\n",
      " [288, 502, 803, 1084, 1289, 1572, 1852, 2109, 2685, 2872, 3124]]\n",
      "[[141, 405, 658, 1746, 2009, 2522, 2780, 3026],\n",
      " [170, 431, 678, 1761, 2031, 2554, 2803, 3046],\n",
      " [183, 446, 706, 1783, 2050, 2566, 2817, 3068],\n",
      " [209, 465, 746, 1809, 2069, 2583, 2839, 3087],\n",
      " [288, 502, 803, 1852, 2109, 2685, 2872, 3124]]\n"
     ]
    }
   ],
   "source": [
    "import copy as cp\n",
    "\n",
    "test = [[141, 405, 658, 1476, 1746, 2009, 2267, 2522, 2780, 3026],\n",
    " [170, 431, 678, 954, 1498, 1761, 2031, 2291, 2554, 2803, 3046],\n",
    " [183, 446, 706, 969, 1237, 1517, 1783, 2050, 2306, 2566, 2817, 3068],\n",
    " [209, 465, 746, 998, 1257, 1536, 1809, 2069, 2326, 2583, 2839, 3087],\n",
    " [288, 502, 803, 1084, 1289, 1572, 1852, 2109, 2685, 2872, 3124]]\n",
    "\n",
    "print(\"Test 1:\")\n",
    "t1 = cp.deepcopy(test)\n",
    "t1[0][0] = None\n",
    "pprint(t1)\n",
    "t1[0].pop(0)\n",
    "pprint(peaks_cleaning(t1))\n",
    "\n",
    "print(\"\\nTest 2:\")\n",
    "t2 = cp.deepcopy(test)\n",
    "t2[2][5] = None\n",
    "pprint(t2)\n",
    "t2[2].pop(5)\n",
    "pk2 = peaks_cleaning(t2)\n",
    "pprint(pk2)\n",
    "\n",
    "# p_t2 = peaks_cleaning(t2)\n",
    "# print(np.array(p_t2[-1])-np.array(p_t2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

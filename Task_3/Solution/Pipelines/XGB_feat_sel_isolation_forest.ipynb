{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neurokit2\n",
      "  Downloading neurokit2-0.0.42-py2.py3-none-any.whl (985 kB)\n",
      "\u001b[K     |████████████████████████████████| 985 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from neurokit2) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from neurokit2) (3.3.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from neurokit2) (1.5.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from neurokit2) (1.1.3)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->neurokit2) (7.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->neurokit2) (2020.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn->neurokit2) (0.23.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->neurokit2) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->neurokit2) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->neurokit2) (2.1.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=add0218d01f2da2867ea2d8718c34c17e0dd7353027677d98fa5e8648c726548\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, neurokit2\n",
      "Successfully installed neurokit2-0.0.42 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Components.feature_extraction' from '../Components/feature_extraction.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "from pprint import pprint\n",
    "\n",
    "# ML\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "\n",
    "# Custom\n",
    "import sys,os\n",
    "sys.path.append( '.' )\n",
    "sys.path.append( '..' )\n",
    "import Components.data_fetching as data_fetching\n",
    "import Components.feature_extraction as feature_extraction\n",
    "\n",
    "# CAREFUL:\n",
    "# If you make changes to a custom module, you have to reload it, i.e rerun this cell\n",
    "import importlib\n",
    "importlib.reload(data_fetching)\n",
    "importlib.reload(feature_extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y = data_fetching.get_train_data()\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_extraction.get_features(types=['timeseries', 'heartbeats', 'peaks'], verbose=True, precomputed='train')\n",
    "X_test = feature_extraction.get_features(types=['timeseries', 'heartbeats', 'peaks'], verbose=True, precomputed='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X,y)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 132)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False,max_iter=5000).fit(X, y)\n",
    "model1 = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5117, 295)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.1, penalty=\"l1\", dual=False,max_iter=5000).fit(X, y)\n",
    "model2 = SelectFromModel(lsvc, prefit=True)\n",
    "X_new2 = model2.transform(X)\n",
    "X_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5117, 407)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False,max_iter=5000).fit(X, y)\n",
    "model3 = SelectFromModel(lsvc, prefit=True)\n",
    "X_new3 = model3.transform(X)\n",
    "X_new3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 132 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = IsolationForest()\n",
    "labels = pd.DataFrame(detector.fit_predict(X_new))\n",
    "labels.where(labels ==  -1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 282 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = IsolationForest()\n",
    "labels2 = pd.DataFrame(detector.fit_predict(X_new2))\n",
    "labels2.where(labels2 ==  -1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 407 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    186\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = IsolationForest()\n",
    "labels3 = pd.DataFrame(detector.fit_predict(X_new2))\n",
    "labels3.where(labels3 ==  -1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(X_new)[labels[0]==1]\n",
    "X1_all = pd.DataFrame(X)[labels[0]==1]\n",
    "y1 = pd.DataFrame(y)[labels[0]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.DataFrame(X_new2)[labels2[0]==1]\n",
    "X2_all = pd.DataFrame(X)[labels2[0]==1]\n",
    "y2 = pd.DataFrame(y)[labels2[0]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame(X_new3)[labels3[0]==1]\n",
    "X3_all = pd.DataFrame(X)[labels3[0]==1]\n",
    "y3 = pd.DataFrame(y)[labels3[0]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83805668 0.80730223 0.83772819 0.80933063 0.82352941 0.81135903\n",
      " 0.81744422 0.78498986 0.80527383 0.8296146 ]\n",
      "0.8164628688275533\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "cv_score = cross_val_score(clf, X3_all, np.ravel(y3), cv=10, scoring='f1_micro')\n",
    "print(cv_score)\n",
    "print(np.mean(cv_score))\n",
    "\n",
    "# 1st attempt\n",
    "# [0.62304688 0.71875    0.76953125 0.74414062 0.73046875 0.72265625\n",
    "# 0.7109375  0.7260274  0.72994129 0.66144814]\n",
    "# 0.7136948079745596\n",
    "\n",
    "# 2nd attempt\n",
    "# [0.73242188 0.74023438 0.83007812 0.7578125  0.75976562 0.74804688\n",
    "# 0.76171875 0.74168297 0.73972603 0.75342466]\n",
    "# 0.7564911784491194\n",
    "\n",
    "# 3rd attempt (luke's features)\n",
    "# [0.72070312 0.76171875 0.82421875 0.76757812 0.78515625 0.75585938\n",
    "# 0.76171875 0.76125245 0.7592955  0.77299413]\n",
    "# 0.7670495199363991\n",
    "\n",
    "# 4th attempt (luke's + lea's features)\n",
    "# [0.80859375 0.79492188 0.83984375 0.81640625 0.80273438 0.80664062\n",
    "# 0.81054688 0.78669276 0.7964775  0.82387476]\n",
    "# 0.8086732509784735\n",
    "\n",
    "# 147 outliers, 132 features\n",
    "#[0.81287726 0.80482897 0.83098592 0.81287726 0.80080483 0.80885312\n",
    "# 0.80684105 0.80885312 0.80885312 0.82293763]\n",
    "# 0.811871227364185\n",
    "\n",
    "# 147 outliers, all features\n",
    "# [0.81086519 0.80885312 0.82092555 0.81891348 0.82092555 0.81891348\n",
    "# 0.80885312 0.80482897 0.81891348 0.81488934]\n",
    "# 0.8146881287726357\n",
    "\n",
    "# 175 outliers, 282 features\n",
    "#[0.82626263 0.80606061 0.85222672 0.82995951 0.82186235 0.81174089\n",
    "# 0.81578947 0.7854251  0.8097166  0.82793522]\n",
    "# 0.8186979102768575\n",
    "\n",
    "#175 outliers, all features\n",
    "#[0.82222222 0.81414141 0.84008097 0.81578947 0.82591093 0.80769231\n",
    "# 0.80566802 0.78744939 0.80769231 0.82591093]\n",
    "#0.8152557968347441\n",
    "\n",
    "\n",
    "# 186 outliers, 407 features\n",
    "#[0.82388664 0.80324544 0.84381339 0.81947262 0.82758621 0.79918864\n",
    "# 0.82758621 0.78904665 0.80730223 0.82150101]\n",
    "#0.8162629033185242\n",
    "\n",
    "# 186 outliers, all features\n",
    "#[0.83805668 0.80730223 0.83772819 0.80933063 0.82352941 0.81135903\n",
    "# 0.81744422 0.78498986 0.80527383 0.8296146 ]\n",
    "# 0.8164628688275533"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.89489420e+00,  7.81544887e+00,  2.15093648e+01, ...,\n",
       "         3.97737220e+04,  3.34860455e+02,  5.75872624e+03],\n",
       "       [-1.39240425e+00, -3.60578697e+00, -9.38433508e+00, ...,\n",
       "         2.88743315e+04,  2.98763070e+02,  2.53179418e+04],\n",
       "       [-1.52947277e+01, -1.50821936e+01, -4.84264497e+00, ...,\n",
       "         2.46291898e+04,  2.12731707e+02,  1.18801808e+04],\n",
       "       ...,\n",
       "       [-3.37235561e+00, -3.68722555e+00, -4.76747246e+00, ...,\n",
       "         7.56773752e+03,  6.74765563e+02,  2.01399210e+04],\n",
       "       [-7.50600703e+00, -7.98755077e+00, -8.89979436e+00, ...,\n",
       "         3.64290068e+03,  2.90524751e+02,  4.49115912e+03],\n",
       "       [-2.12324291e+01, -2.36653252e+01, -2.93271230e+01, ...,\n",
       "         1.66350723e+04,  1.29254520e+02,  1.67198960e+04]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.207445</td>\n",
       "      <td>-1.077014</td>\n",
       "      <td>-0.465150</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>0.169288</td>\n",
       "      <td>0.364732</td>\n",
       "      <td>1.900224</td>\n",
       "      <td>2.540893</td>\n",
       "      <td>2.715229</td>\n",
       "      <td>2.772068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128977</td>\n",
       "      <td>-0.209588</td>\n",
       "      <td>0.243606</td>\n",
       "      <td>-0.028901</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>0.724785</td>\n",
       "      <td>0.151860</td>\n",
       "      <td>-2.358313</td>\n",
       "      <td>0.542786</td>\n",
       "      <td>-0.028901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.293609</td>\n",
       "      <td>-0.245896</td>\n",
       "      <td>-0.136164</td>\n",
       "      <td>-0.324117</td>\n",
       "      <td>-0.357011</td>\n",
       "      <td>-0.366695</td>\n",
       "      <td>-0.361654</td>\n",
       "      <td>-0.346795</td>\n",
       "      <td>-0.322569</td>\n",
       "      <td>-0.282101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293377</td>\n",
       "      <td>-0.321029</td>\n",
       "      <td>-0.266906</td>\n",
       "      <td>-0.301451</td>\n",
       "      <td>0.723277</td>\n",
       "      <td>-0.322853</td>\n",
       "      <td>-0.314583</td>\n",
       "      <td>0.650412</td>\n",
       "      <td>-0.329352</td>\n",
       "      <td>-0.301451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.365646</td>\n",
       "      <td>-0.381506</td>\n",
       "      <td>-0.402769</td>\n",
       "      <td>-0.100828</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>0.164993</td>\n",
       "      <td>0.919332</td>\n",
       "      <td>1.184230</td>\n",
       "      <td>1.224577</td>\n",
       "      <td>1.184086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139184</td>\n",
       "      <td>-0.266910</td>\n",
       "      <td>-0.288153</td>\n",
       "      <td>-0.241744</td>\n",
       "      <td>0.637660</td>\n",
       "      <td>0.059849</td>\n",
       "      <td>-0.155536</td>\n",
       "      <td>-0.465861</td>\n",
       "      <td>-0.264362</td>\n",
       "      <td>-0.241744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.159694</td>\n",
       "      <td>-0.066373</td>\n",
       "      <td>0.402640</td>\n",
       "      <td>1.146236</td>\n",
       "      <td>1.241920</td>\n",
       "      <td>1.283473</td>\n",
       "      <td>1.145250</td>\n",
       "      <td>0.876626</td>\n",
       "      <td>0.688014</td>\n",
       "      <td>0.463570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335035</td>\n",
       "      <td>0.442495</td>\n",
       "      <td>-0.160687</td>\n",
       "      <td>0.295278</td>\n",
       "      <td>-0.408963</td>\n",
       "      <td>-0.163615</td>\n",
       "      <td>-0.185712</td>\n",
       "      <td>-1.266993</td>\n",
       "      <td>-0.069152</td>\n",
       "      <td>0.295278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.134172</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.599467</td>\n",
       "      <td>1.073789</td>\n",
       "      <td>1.103155</td>\n",
       "      <td>1.107585</td>\n",
       "      <td>1.012569</td>\n",
       "      <td>0.832517</td>\n",
       "      <td>0.690201</td>\n",
       "      <td>0.495885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283694</td>\n",
       "      <td>-0.314030</td>\n",
       "      <td>-0.288856</td>\n",
       "      <td>-0.276008</td>\n",
       "      <td>0.089927</td>\n",
       "      <td>-0.298641</td>\n",
       "      <td>-0.283341</td>\n",
       "      <td>0.770911</td>\n",
       "      <td>-0.318934</td>\n",
       "      <td>-0.276008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>-0.066402</td>\n",
       "      <td>-0.070081</td>\n",
       "      <td>-0.078597</td>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.063347</td>\n",
       "      <td>0.116320</td>\n",
       "      <td>0.307888</td>\n",
       "      <td>0.421201</td>\n",
       "      <td>0.482262</td>\n",
       "      <td>0.517692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029167</td>\n",
       "      <td>-0.066845</td>\n",
       "      <td>-0.205251</td>\n",
       "      <td>0.106060</td>\n",
       "      <td>0.894606</td>\n",
       "      <td>0.346930</td>\n",
       "      <td>0.168004</td>\n",
       "      <td>1.440452</td>\n",
       "      <td>0.061414</td>\n",
       "      <td>0.106060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>-0.149662</td>\n",
       "      <td>-0.071581</td>\n",
       "      <td>0.127683</td>\n",
       "      <td>0.440597</td>\n",
       "      <td>0.517252</td>\n",
       "      <td>0.586784</td>\n",
       "      <td>0.912797</td>\n",
       "      <td>1.060800</td>\n",
       "      <td>1.118398</td>\n",
       "      <td>1.157561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292065</td>\n",
       "      <td>-0.321948</td>\n",
       "      <td>-0.267140</td>\n",
       "      <td>-0.298560</td>\n",
       "      <td>0.206076</td>\n",
       "      <td>-0.308653</td>\n",
       "      <td>-0.306974</td>\n",
       "      <td>-2.641901</td>\n",
       "      <td>-0.307532</td>\n",
       "      <td>-0.298560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.514600</td>\n",
       "      <td>-0.246348</td>\n",
       "      <td>-1.729328</td>\n",
       "      <td>-1.977844</td>\n",
       "      <td>-2.133972</td>\n",
       "      <td>-2.085621</td>\n",
       "      <td>-1.628745</td>\n",
       "      <td>-1.334222</td>\n",
       "      <td>-1.007282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204562</td>\n",
       "      <td>-0.234094</td>\n",
       "      <td>-0.221259</td>\n",
       "      <td>-0.246264</td>\n",
       "      <td>-0.655173</td>\n",
       "      <td>-0.253016</td>\n",
       "      <td>-0.278705</td>\n",
       "      <td>0.807336</td>\n",
       "      <td>-0.323164</td>\n",
       "      <td>-0.246264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>1.704047</td>\n",
       "      <td>1.692566</td>\n",
       "      <td>1.466434</td>\n",
       "      <td>0.970626</td>\n",
       "      <td>0.838402</td>\n",
       "      <td>0.719555</td>\n",
       "      <td>0.395529</td>\n",
       "      <td>0.265884</td>\n",
       "      <td>0.199884</td>\n",
       "      <td>0.122699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270944</td>\n",
       "      <td>-0.306381</td>\n",
       "      <td>-0.236215</td>\n",
       "      <td>-0.267191</td>\n",
       "      <td>1.312352</td>\n",
       "      <td>-0.270141</td>\n",
       "      <td>-0.263045</td>\n",
       "      <td>-1.769179</td>\n",
       "      <td>-0.260061</td>\n",
       "      <td>-0.267191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>0.230040</td>\n",
       "      <td>0.306287</td>\n",
       "      <td>0.572246</td>\n",
       "      <td>0.936406</td>\n",
       "      <td>0.927575</td>\n",
       "      <td>0.854768</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>-0.191476</td>\n",
       "      <td>-0.364107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271917</td>\n",
       "      <td>-0.296864</td>\n",
       "      <td>-0.260362</td>\n",
       "      <td>-0.271051</td>\n",
       "      <td>-0.656173</td>\n",
       "      <td>-0.302359</td>\n",
       "      <td>-0.220299</td>\n",
       "      <td>0.201618</td>\n",
       "      <td>-0.338718</td>\n",
       "      <td>-0.271051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4942 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -1.207445 -1.077014 -0.465150  0.053371  0.169288  0.364732  1.900224   \n",
       "1    -0.293609 -0.245896 -0.136164 -0.324117 -0.357011 -0.366695 -0.361654   \n",
       "2    -0.365646 -0.381506 -0.402769 -0.100828  0.022463  0.164993  0.919332   \n",
       "3    -0.159694 -0.066373  0.402640  1.146236  1.241920  1.283473  1.145250   \n",
       "5    -0.134172  0.033715  0.599467  1.073789  1.103155  1.107585  1.012569   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5111 -0.066402 -0.070081 -0.078597  0.016341  0.063347  0.116320  0.307888   \n",
       "5113 -0.149662 -0.071581  0.127683  0.440597  0.517252  0.586784  0.912797   \n",
       "5114  0.642301  0.514600 -0.246348 -1.729328 -1.977844 -2.133972 -2.085621   \n",
       "5115  1.704047  1.692566  1.466434  0.970626  0.838402  0.719555  0.395529   \n",
       "5116  0.230040  0.306287  0.572246  0.936406  0.927575  0.854768  0.308958   \n",
       "\n",
       "           7         8         9    ...       272       273       274  \\\n",
       "0     2.540893  2.715229  2.772068  ...  0.128977 -0.209588  0.243606   \n",
       "1    -0.346795 -0.322569 -0.282101  ... -0.293377 -0.321029 -0.266906   \n",
       "2     1.184230  1.224577  1.184086  ... -0.139184 -0.266910 -0.288153   \n",
       "3     0.876626  0.688014  0.463570  ...  0.335035  0.442495 -0.160687   \n",
       "5     0.832517  0.690201  0.495885  ... -0.283694 -0.314030 -0.288856   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5111  0.421201  0.482262  0.517692  ... -0.029167 -0.066845 -0.205251   \n",
       "5113  1.060800  1.118398  1.157561  ... -0.292065 -0.321948 -0.267140   \n",
       "5114 -1.628745 -1.334222 -1.007282  ... -0.204562 -0.234094 -0.221259   \n",
       "5115  0.265884  0.199884  0.122699  ... -0.270944 -0.306381 -0.236215   \n",
       "5116 -0.016032 -0.191476 -0.364107  ... -0.271917 -0.296864 -0.260362   \n",
       "\n",
       "           275       276       277       278       279       280       281  \n",
       "0    -0.028901 -0.026775  0.724785  0.151860 -2.358313  0.542786 -0.028901  \n",
       "1    -0.301451  0.723277 -0.322853 -0.314583  0.650412 -0.329352 -0.301451  \n",
       "2    -0.241744  0.637660  0.059849 -0.155536 -0.465861 -0.264362 -0.241744  \n",
       "3     0.295278 -0.408963 -0.163615 -0.185712 -1.266993 -0.069152  0.295278  \n",
       "5    -0.276008  0.089927 -0.298641 -0.283341  0.770911 -0.318934 -0.276008  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5111  0.106060  0.894606  0.346930  0.168004  1.440452  0.061414  0.106060  \n",
       "5113 -0.298560  0.206076 -0.308653 -0.306974 -2.641901 -0.307532 -0.298560  \n",
       "5114 -0.246264 -0.655173 -0.253016 -0.278705  0.807336 -0.323164 -0.246264  \n",
       "5115 -0.267191  1.312352 -0.270141 -0.263045 -1.769179 -0.260061 -0.267191  \n",
       "5116 -0.271051 -0.656173 -0.302359 -0.220299  0.201618 -0.338718 -0.271051  \n",
       "\n",
       "[4942 rows x 282 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X2,np.ravel(y2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_transf = pd.DataFrame(model2.transform(X_test_sc))\n",
    "y_pred = clf.predict(X_test_transf)\n",
    "plt.hist(y_pred)\n",
    "\n",
    "y_pred_pd = pd.DataFrame(data=y_pred, columns=[\"y\"])\n",
    "y_pred_pd.to_csv('../../Predictions/XGB_175outliers_282features.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
